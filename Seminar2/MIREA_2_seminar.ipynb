{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MRuSrP7JQ00i",
        "1b95Z8u7Q3OL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Разбор практики 1.**"
      ],
      "metadata": {
        "id": "RQ8rTFmQ0ueR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 2**. Cделать нейрон, соответствующий оператору НЕ."
      ],
      "metadata": {
        "id": "9P9bWaC9QQJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "class Neuron(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc = torch.nn.Linear(1, 1, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"
      ],
      "metadata": {
        "id": "Hh8sSJkEWNmT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = Neuron()\n",
        "neuron.fc.weight, neuron.fc.bias"
      ],
      "metadata": {
        "id": "r9HoH1koVQXi",
        "outputId": "2b940d2e-5754-4840-abb2-b66098c403e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[0.6294]], requires_grad=True), Parameter containing:\n",
              " tensor([0.1874], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.fc.weight.data = torch.tensor([[-1.0]])\n",
        "neuron.fc.bias.data = torch.tensor([1.0])\n",
        "neuron.fc.weight, neuron.fc.bias"
      ],
      "metadata": {
        "id": "MLmGhtWFTYlV",
        "outputId": "6cb89837-a8a4-43b3-e687-ff8753f7c3cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[-1.]], requires_grad=True), Parameter containing:\n",
              " tensor([1.], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0])\n",
        "neuron(x)"
      ],
      "metadata": {
        "id": "UFr5InkDTf-r",
        "outputId": "16c30331-0fb5-49a1-f46c-1bf8def929fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0])\n",
        "neuron(x)"
      ],
      "metadata": {
        "id": "sXJqgPEwAwHa",
        "outputId": "47fbfb17-0088-401e-e143-402b56d321a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 3**. Cделать нейрон, соответствующий оператору И."
      ],
      "metadata": {
        "id": "TRxJxcRJQsMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc = torch.nn.Linear(2, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"
      ],
      "metadata": {
        "id": "7dvDtA7HX3V6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = Neuron()\n",
        "neuron.fc.weight, neuron.fc.bias"
      ],
      "metadata": {
        "id": "olMqAnQtX5NQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12aaf459-1a53-49c8-bd44-8df50ffed8da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[-0.6043,  0.6443]], requires_grad=True), Parameter containing:\n",
              " tensor([-0.0518], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.fc.weight.data = torch.tensor([[1.0, 1.0]])\n",
        "neuron.fc.bias.data = torch.tensor([-1.5])\n",
        "neuron.fc.weight, neuron.fc.bias"
      ],
      "metadata": {
        "id": "kAtwMX7HQ0aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af14c5ea-e18d-46dc-96c6-baf46dfcdf27"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[1., 1.]], requires_grad=True), Parameter containing:\n",
              " tensor([-1.5000], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0, 0.0])\n",
        "neuron(x)"
      ],
      "metadata": {
        "id": "P27EdNkrXloh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9542b2c0-e48f-4a48-a9d5-9dea5bd674ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 0.0 ])\n",
        "neuron(x)"
      ],
      "metadata": {
        "outputId": "5f3d561e-184d-4760-b7b4-3381d129ec59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BJc_ipGrei3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0, 1.0 ])\n",
        "neuron(x)"
      ],
      "metadata": {
        "outputId": "d3021877-ea7b-4f06-c318-904a2edc0fb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjVTdBf-rei5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 1.0 ])\n",
        "neuron(x)"
      ],
      "metadata": {
        "outputId": "bc505aa2-4cb2-441d-82ac-c003de3b9f1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyomxCJUrei5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 4**. Cделать нейрон, соответствующий оператору ИЛИ."
      ],
      "metadata": {
        "id": "MRuSrP7JQ00i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.fc.weight.data = torch.tensor([[1., 1.]])\n",
        "neuron.fc.bias.data = torch.tensor([-0.5])"
      ],
      "metadata": {
        "id": "23RuhFqbQ24-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0, 0.0])\n",
        "neuron(x)"
      ],
      "metadata": {
        "id": "i-BZHFqnXpLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c806cfdd-28fa-432e-e183-3b3ea8cd9c32"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 0.0 ])\n",
        "neuron(x)"
      ],
      "metadata": {
        "outputId": "558fac1b-31df-48dd-baa5-5370f3718d65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZuFtRlvyixQ"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0, 1.0 ])\n",
        "neuron(x)"
      ],
      "metadata": {
        "outputId": "314bc07a-4a49-41e4-caea-e141bbb3c882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyu88Kg0yixR"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1.0, 1.0 ])\n",
        "neuron(x)"
      ],
      "metadata": {
        "outputId": "d18c682d-6788-4a65-be8b-e1f92ef4d33e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2OhYEC7yixS"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Задача 5**. Cделать нейрон, соответствующий оператору XOR."
      ],
      "metadata": {
        "id": "1b95Z8u7Q3OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.fc.weight.data = torch.tensor([[0.0, 0.0]])\n",
        "neuron.fc.bias.data = torch.tensor([0.0])"
      ],
      "metadata": {
        "id": "hWP7ee7tjCGv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([0.0, 0.0])\n",
        "neuron(x)"
      ],
      "metadata": {
        "id": "HgDrZ7PBjGwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13df3578-2873-4d88-8dea-a6991cd43d21"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Занятие 2.**"
      ],
      "metadata": {
        "id": "zjM7DFps2rBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Pytorch autograd](https://pytorch.org/docs/stable/autograd.html)"
      ],
      "metadata": {
        "id": "KlS1ciOPBg7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Tutorial](https://www.youtube.com/watch?v=MswxJw-8PvE)\n",
        "\n",
        "[Slides](https://app.diagrams.net/#G1bq3akhmA5DGRCiFYJfNPSn7il2wvCkEY)\n",
        "\n",
        "[Torch C++ Binary operations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp)\n",
        "\n",
        "[Torch C++ Activations](https://github.com/pytorch/pytorch/blob/c5872e6d6d8fd9b8439b914c143d49488335f573/aten/src/ATen/native/cpu/Activation.cpp)"
      ],
      "metadata": {
        "id": "kP06X1SrzLlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "alR-VHX_gnQK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_tensor_params(*tensors):\n",
        "  for x in tensors:\n",
        "    print('---')\n",
        "    print(f\"data - {x.data}\")\n",
        "    print(f\"grad - {x.grad}\")\n",
        "    print(f\"grad_fn - {x.grad_fn}\")\n",
        "    print(f\"req_grad - {x.requires_grad}\")\n",
        "    print(f\"is_leaf - {x.is_leaf}\")"
      ],
      "metadata": {
        "id": "ipOjjh8OCk4u"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(5.0)\n",
        "show_tensor_params(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXas0qEnybl9",
        "outputId": "3e07e327-783f-4a8d-87d9-18137ed3339e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "data - 5.0\n",
            "grad - None\n",
            "grad_fn - None\n",
            "req_grad - False\n",
            "is_leaf - True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All Tensors that have **requires_grad** which is **False** will be leaf Tensors by convention.\n",
        "\n",
        "For Tensors that have **requires_grad** which is **True**, they will be leaf Tensors if they were created by the user. This means that they are not the result of an operation and so **grad_fn** is None.\n",
        "\n",
        "Only leaf Tensors will have their **grad** populated during a call to backward(). To get grad populated for non-leaf Tensors, you can use retain_grad().[[Link]](https://pytorch.org/docs/stable/generated/torch.Tensor.is_leaf.html#torch.Tensor.is_leaf)"
      ],
      "metadata": {
        "id": "NuymHxbjzDfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Slide A4\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(3.0)\n",
        "c = a*b\n",
        "\n",
        "c.backward()\n",
        "# (2 * c).backward()"
      ],
      "metadata": {
        "id": "O5NE4zRPyqTT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tensor_params(a, b, c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-TbdvmH-oaM",
        "outputId": "fad44ac3-0220-4404-e7cf-1ba08c7f52b5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "data - 2.0\n",
            "grad - 3.0\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n",
            "---\n",
            "data - 3.0\n",
            "grad - None\n",
            "grad_fn - None\n",
            "req_grad - False\n",
            "is_leaf - True\n",
            "---\n",
            "data - 6.0\n",
            "grad - None\n",
            "grad_fn - <MulBackward0 object at 0x7f7c1a872670>\n",
            "req_grad - True\n",
            "is_leaf - False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-168b1ceafb31>:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n",
            "  print(f\"grad - {x.grad}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Slide Simple5"
      ],
      "metadata": {
        "id": "NqUcFO2rCXni"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(3.0, requires_grad=True)\n",
        "c = a*b\n",
        "d = torch.tensor(4.0, requires_grad=True)\n",
        "e = c*d\n",
        "\n",
        "c.retain_grad()\n",
        "e.retain_grad()\n",
        "e.backward()"
      ],
      "metadata": {
        "id": "gYTsuKc3Fn8r"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tensor_params(a, b, c, d, e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egTBJvIBF5EO",
        "outputId": "43cb161f-29f6-43ff-d3e9-177818f8934a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "data - 2.0\n",
            "grad - 12.0\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n",
            "---\n",
            "data - 3.0\n",
            "grad - 8.0\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n",
            "---\n",
            "data - 6.0\n",
            "grad - 4.0\n",
            "grad_fn - <MulBackward0 object at 0x7f7ba1ad3820>\n",
            "req_grad - True\n",
            "is_leaf - False\n",
            "---\n",
            "data - 4.0\n",
            "grad - 6.0\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n",
            "---\n",
            "data - 24.0\n",
            "grad - 1.0\n",
            "grad_fn - <MulBackward0 object at 0x7f7ba1ad3b50>\n",
            "req_grad - True\n",
            "is_leaf - False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In place 1\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(3.0, requires_grad=True)\n",
        "c = a*b\n",
        "d = torch.tensor(4.0, requires_grad=True)\n",
        "e = c*d\n",
        "c += 1\n",
        "\n",
        "e.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "W5Cs2_REGgOS",
        "outputId": "47849a64-f084-4ff6-eed6-16c1bd769741"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-3de2fcb7bcd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor []], which is output 0 of AddBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(c._version)\n",
        "print(d._version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WeqfWzYGhKG",
        "outputId": "a93bf42f-9a05-4f0c-e606-994f7b0b3d5c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In place 2\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = torch.tensor(3.0, requires_grad=True)\n",
        "c = a*b\n",
        "d = torch.tensor(4.0, requires_grad=True)\n",
        "e = c+d\n",
        "c += 1\n",
        "\n",
        "e.backward()"
      ],
      "metadata": {
        "id": "iLZ3Z4qIH4J4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(c._version)\n",
        "print(d._version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ySSjlRUIH0e",
        "outputId": "dcb1f0d0-b95c-4649-ab9e-6e53798501e7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# отвязка от графа\n",
        "k = e.detach()"
      ],
      "metadata": {
        "id": "4jbSqPGkILEw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.storage == e.storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLKUQ08AJhZT",
        "outputId": "6bf3a31b-e53b-47ec-9c7e-a15ce116a6aa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_tensor_params(e, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqo-PW2kJkaG",
        "outputId": "d5deb93a-d05e-476b-a439-7db143e7a84f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "data - 10.0\n",
            "grad - None\n",
            "grad_fn - <AddBackward0 object at 0x7f7ba1ad3df0>\n",
            "req_grad - True\n",
            "is_leaf - False\n",
            "---\n",
            "data - 10.0\n",
            "grad - None\n",
            "grad_fn - None\n",
            "req_grad - False\n",
            "is_leaf - True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-168b1ceafb31>:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n",
            "  print(f\"grad - {x.grad}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание собственной библиотеки автоматического дифференцирования"
      ],
      "metadata": {
        "id": "B8urvcsAKi62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "txwYkEHMftme"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Простой пример"
      ],
      "metadata": {
        "id": "urGQXw9GgdQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  return 3*x**2 - 4*x + 5"
      ],
      "metadata": {
        "id": "bPNsEPbZfwXm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f(3.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKMjYubGfzo5",
        "outputId": "c3ee2425-16ae-4a32-f8e7-0aa653c1f537"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs = np.arange(-5, 5, 0.25)\n",
        "ys = f(xs)\n",
        "plt.plot(xs, ys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "2Mufja5Mf2dD",
        "outputId": "342d3c15-832b-43d9-c2e4-6df281fb4817"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7ba1a6a8b0>]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = 0.000001\n",
        "x = 2\n",
        "(f(x + h) - f(x))/h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzRAdjhFgGo8",
        "outputId": "a2fefbd7-0d58-4f1f-ce72-f87ec7734166"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.000003001384925"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Более сложный пример"
      ],
      "metadata": {
        "id": "dOszwXaTgkd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 2.0\n",
        "b = -3.0\n",
        "c = 10.0\n",
        "d = a*b + c\n",
        "print(d)"
      ],
      "metadata": {
        "id": "BOzPl8NWghve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b3e8b6-e22e-42ab-fddd-64910abf9fbd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = 0.0001\n",
        "\n",
        "# inputs\n",
        "a = 2.0\n",
        "b = -3.0\n",
        "c = 10.0\n",
        "\n",
        "d1 = a*b + c\n",
        "c += h\n",
        "d2 = a*b + c\n",
        "\n",
        "print('d1', d1)\n",
        "print('d2', d2)\n",
        "print('slope', (d2 - d1)/h)"
      ],
      "metadata": {
        "id": "P9Xx4_omgrkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726d520e-aced-4688-b353-b102e6b98155"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d1 4.0\n",
            "d2 4.0001\n",
            "slope 0.9999999999976694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wle8vv7_grKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://pytorch.org/tutorials/beginner/examples_autograd/polynomial_custom_function.html"
      ],
      "metadata": {
        "id": "dlDJrMMsOgNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Function"
      ],
      "metadata": {
        "id": "sPyPkdq5RH94"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Exp(Function):\n",
        "  \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  def forward(ctx, i):\n",
        "    \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "    \"\"\"\n",
        "    result = i.exp()\n",
        "    ctx.save_for_backward(result)\n",
        "    return result\n",
        "\n",
        "  @staticmethod\n",
        "  def backward(ctx, grad_output):\n",
        "    \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "    \"\"\"\n",
        "    print(ctx.saved_tensors)\n",
        "    result, = ctx.saved_tensors\n",
        "    return grad_output * result"
      ],
      "metadata": {
        "id": "F5-hnsEiPIz9"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use it by calling the apply method\n",
        "input = torch.tensor(2.0, requires_grad=True)\n",
        "output = Exp.apply(input)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elaOA8bdRiMc",
        "outputId": "458930bb-9430-44fe-9f24-28bbf29455c0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.3891, grad_fn=<ExpBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "math.exp(2.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlcZLt-RSGgG",
        "outputId": "c9da97fe-4f01-497c-9172-67b308ee7ffa"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.38905609893065"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.backward()\n",
        "show_tensor_params(output)\n",
        "show_tensor_params(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om6dn414SQeA",
        "outputId": "93a6fbec-abe2-4951-9948-b494bd9b81d0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor(7.3891, grad_fn=<ExpBackward>),)\n",
            "---\n",
            "data - 7.389056205749512\n",
            "grad - None\n",
            "grad_fn - <torch.autograd.function.ExpBackward object at 0x7f7ba1e6cb80>\n",
            "req_grad - True\n",
            "is_leaf - False\n",
            "---\n",
            "data - 2.0\n",
            "grad - 7.389056205749512\n",
            "grad_fn - None\n",
            "req_grad - True\n",
            "is_leaf - True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-168b1ceafb31>:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n",
            "  print(f\"grad - {x.grad}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание**: реализуйте backward для Polynomial 0.5 * (5 * input ** 3 - 3 * input)"
      ],
      "metadata": {
        "id": "d_14IqfeSnLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class Polynomial(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "        \"\"\"\n",
        "        ctx.save_for_backward(input)\n",
        "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "        \"\"\"\n",
        "        input, = ctx.saved_tensors\n",
        "        return (7.5 * input ** 2 - 1.5) * grad_output"
      ],
      "metadata": {
        "id": "i5cNegVYOd8u"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Практическое задание: написать собственный движок автоматического дифференцирования, а именно: реализовать"
      ],
      "metadata": {
        "id": "fA2PNhudUNij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "class Value:\n",
        "    \"\"\" stores a single scalar value and its gradient \"\"\"\n",
        "\n",
        "    def __init__(self, data, _children=(), _op=''):\n",
        "        self.data = data\n",
        "        self.grad = 0\n",
        "        # internal variables used for autograd graph construction\n",
        "        self._backward = lambda: None # function \n",
        "        self._prev = set(_children) # set of Value objects\n",
        "        self._op = _op # the op that produced this node, string ('+', '-', ....)\n",
        "\n",
        "\n",
        "    def __add__(self, other):\n",
        "        other = other if isinstance(other, Value) else Value(other)\n",
        "        out = Value(self.data + other.data, _children=(self, other)) # \n",
        "\n",
        "        def _backward():\n",
        "            self.grad += out.grad #\n",
        "            other.grad += out.grad #\n",
        "        out._backward = _backward\n",
        "\n",
        "        return out\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        other = other if isinstance(other, Value) else Value(other)\n",
        "        out = Value(self.data * other.data, _children=(self, other))\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += out.grad * other.data\n",
        "            other.grad += out.grad * self.data\n",
        "        out._backward = _backward\n",
        "\n",
        "        return out\n",
        "\n",
        "    def __pow__(self, other):\n",
        "        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
        "        out = Value(self.data ** other, _children=(self,))\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += (out.grad * other * self.data ** (other - 1))\n",
        "        out._backward = _backward\n",
        "\n",
        "        return out\n",
        "\n",
        "    def relu(self):\n",
        "        out = Value(max(0,self.data), _children=(self,))\n",
        "        \n",
        "        derivative = 1 if self.data > 0 else 0\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += out.grad * derivative\n",
        "        out._backward = _backward\n",
        "\n",
        "        return out\n",
        "    \n",
        "    # task 3\n",
        "    def exp(self):\n",
        "        out = Value(math.e ** self.data, _children=(self,))\n",
        "        def _backward():\n",
        "            self.grad += out.grad * math.e ** self.data\n",
        "        out._backward = _backward\n",
        "      \n",
        "\n",
        "    def backward(self):\n",
        "\n",
        "        # topological order all of the children in the graph\n",
        "        topo = []\n",
        "        visited = set()\n",
        "        def build_topo(v):\n",
        "            if v not in visited:\n",
        "                visited.add(v)\n",
        "                for child in v._prev:\n",
        "                    build_topo(child)\n",
        "                topo.append(v)\n",
        "        build_topo(self)\n",
        "\n",
        "        # go one variable at a time and apply the chain rule to get its gradient\n",
        "        self.grad = 1\n",
        "        for v in reversed(topo):\n",
        "            v._backward()\n",
        "\n",
        "    def __neg__(self): # -self\n",
        "        return self * -1\n",
        "\n",
        "    def __radd__(self, other): # other + self\n",
        "        return self + other\n",
        "\n",
        "    def __sub__(self, other): # self - other\n",
        "        return self + (-other)\n",
        "\n",
        "    def __rsub__(self, other): # other - self\n",
        "        return other + (-self)\n",
        "\n",
        "    def __rmul__(self, other): # other * self\n",
        "        return self * other\n",
        "\n",
        "    def __truediv__(self, other): # self / other\n",
        "        return self * other**-1\n",
        "\n",
        "    def __rtruediv__(self, other): # other / self\n",
        "        return other * self**-1\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Value(data={self.data}, grad={self.grad})\""
      ],
      "metadata": {
        "id": "chDdD9oSUlUJ"
      },
      "execution_count": 781,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_sanity_check():\n",
        "\n",
        "    x = Value(-4.0)\n",
        "    z = 2 * x + 2 + x\n",
        "  \n",
        "    q = z.relu() + z * x\n",
        "    h = (z * z).relu()\n",
        "    y = h + q + q * x\n",
        "    y.backward()\n",
        "    xmg, ymg = x, y\n",
        "\n",
        "    x = torch.Tensor([-4.0]).double()\n",
        "    x.requires_grad = True\n",
        "    z = 2 * x + 2 + x\n",
        "    q = z.relu() + z * x\n",
        "    h = (z * z).relu()\n",
        "    y = h + q + q * x\n",
        "    y.backward()\n",
        "    xpt, ypt = x, y\n",
        "\n",
        "    \n",
        "    # forward pass went well\n",
        "    assert ymg.data == ypt.data.item()\n",
        "    # backward pass went well\n",
        "    print(xmg, xpt, xpt.grad)\n",
        "    assert xmg.grad == xpt.grad.item()\n",
        "\n",
        "\n",
        "def test_more_ops():\n",
        "\n",
        "    a = Value(-4.0)\n",
        "    b = Value(2.0)\n",
        "    c = a + b\n",
        "    d = a * b + b**3\n",
        "    c += c + 1\n",
        "    c += 1 + c + (-a)\n",
        "    d += d * 2 + (b + a).relu()\n",
        "    d += 3 * d + (b - a).relu()\n",
        "    e = c - d\n",
        "    f = e**2\n",
        "    g = f / 2.0\n",
        "    g += 10.0 / f\n",
        "    g.backward()\n",
        "    amg, bmg, gmg = a, b, g\n",
        "\n",
        "    a = torch.Tensor([-4.0]).double()\n",
        "    b = torch.Tensor([2.0]).double()\n",
        "    a.requires_grad = True\n",
        "    b.requires_grad = True\n",
        "    c = a + b\n",
        "    d = a * b + b**3\n",
        "    c = c + c + 1\n",
        "    c = c + 1 + c + (-a)\n",
        "    d = d + d * 2 + (b + a).relu()\n",
        "    d = d + 3 * d + (b - a).relu()\n",
        "    e = c - d\n",
        "    f = e**2\n",
        "    g = f / 2.0\n",
        "    g = g + 10.0 / f\n",
        "    g.backward()\n",
        "    apt, bpt, gpt = a, b, g\n",
        "\n",
        "    tol = 1e-6\n",
        "    # forward pass went well\n",
        "    assert abs(gmg.data - gpt.data.item()) < tol\n",
        "    # backward pass went well\n",
        "    assert abs(amg.grad - apt.grad.item()) < tol\n",
        "    assert abs(bmg.grad - bpt.grad.item()) < tol"
      ],
      "metadata": {
        "id": "vY7OzWjuUiaa"
      },
      "execution_count": 782,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Test:\n",
        "  def __init__(self):\n",
        "    self.a = 0\n",
        "  def __repr__(self):\n",
        "    return str(self.a)\n",
        "\n",
        "t = set([Test() for _ in range(5)])\n",
        "for item in t:\n",
        "  item.a = 5\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VikIbCXHnxK",
        "outputId": "5cf2e106-abb9-4994-a05b-ca03927ddc7f"
      },
      "execution_count": 783,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{5, 5, 5, 5, 5}"
            ]
          },
          "metadata": {},
          "execution_count": 783
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = Value(-4.0)\n",
        "b = Value(2.0)\n",
        "d = Value(3.0)"
      ],
      "metadata": {
        "id": "1LgTiYeZ-WGk"
      },
      "execution_count": 784,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = a + b\n",
        "e = c * d\n",
        "e.backward()"
      ],
      "metadata": {
        "id": "Y0svSAs2h0Ap"
      },
      "execution_count": 785,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c, d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rS-GInvEHrw",
        "outputId": "ce4947c9-252f-4a15-9aa2-666421a28e98"
      },
      "execution_count": 786,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Value(data=-2.0, grad=3.0), Value(data=3.0, grad=-2.0))"
            ]
          },
          "metadata": {},
          "execution_count": 786
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a, b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9u8SieUFBjI",
        "outputId": "cbf1348d-d968-4148-ad6e-4f8a83e0d26f"
      },
      "execution_count": 787,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Value(data=-4.0, grad=3.0), Value(data=2.0, grad=3.0))"
            ]
          },
          "metadata": {},
          "execution_count": 787
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([-4.0],requires_grad=True)\n",
        "b = torch.tensor([2.0],requires_grad=True)\n",
        "d = torch.tensor([3.0],requires_grad=True)\n",
        "\n",
        "c = a + b\n",
        "e = c * d\n",
        "e.backward()\n",
        "e.grad, c.grad, d.grad, a.grad, b.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5fzC9Kp2P-E",
        "outputId": "208f2e27-8128-430e-b71d-8b655e8caf48"
      },
      "execution_count": 788,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-788-b9dad4f04d3a>:8: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:480.)\n",
            "  e.grad, c.grad, d.grad, a.grad, b.grad\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, tensor([-2.]), tensor([3.]), tensor([3.]))"
            ]
          },
          "metadata": {},
          "execution_count": 788
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG_BpYZdsR9b",
        "outputId": "fde26256-49d6-4f59-b3ba-6db1ddfc121b"
      },
      "execution_count": 789,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.])"
            ]
          },
          "metadata": {},
          "execution_count": 789
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sanity_check()"
      ],
      "metadata": {
        "id": "w9n8DN6RYkrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90541707-7fc6-4503-f3cb-c0148d8d751b"
      },
      "execution_count": 790,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value(data=-4.0, grad=46.0) tensor([-4.], dtype=torch.float64, requires_grad=True) tensor([46.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_more_ops()"
      ],
      "metadata": {
        "id": "1T198QDQYh_q"
      },
      "execution_count": 791,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение на основе собственной бибилотеки"
      ],
      "metadata": {
        "id": "o-KbDOhMYHZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Многослойный перцептрон на основе класса Value"
      ],
      "metadata": {
        "id": "uVK1JLXom0Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from functools import reduce\n",
        "class Module:\n",
        "\n",
        "    def zero_grad(self):\n",
        "      for p in self.parameters():\n",
        "        p.grad = 0\n",
        "\n",
        "    # def parameters():\n",
        "    #     return []\n",
        "\n",
        "class Neuron(Module):\n",
        "\n",
        "    def __init__(self, nin, nonlin=True):\n",
        "        self.w = [Value(random.gauss(0,1)) for _ in range(nin)]\n",
        "        self.b = Value(random.gauss(0,1))\n",
        "        self.nonlin = nonlin\n",
        "\n",
        "    def __call__(self, x):\n",
        "        act = sum([xi * wi for xi, wi in zip(x, self.w)]) + self.b\n",
        "        return act.relu() if self.nonlin else act\n",
        "\n",
        "    def parameters(self):\n",
        "        return self.w + [self.b]\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{'ReLU' if self.nonlin else 'Linear'}Neuron({len(self.w)})\"\n",
        "\n",
        "class Layer(Module):\n",
        "\n",
        "    def __init__(self, nin, nout, **kwargs):\n",
        "        self.neurons = [Neuron(nin, kwargs['nonlin']) for _ in range(nout)]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        out = []\n",
        "        for xi in x:\n",
        "            res = [neuron(xi) for neuron in self.neurons]\n",
        "            out.append(res[0] if len(res) == 1 else res)\n",
        "        return out[0] if len(out) == 1 else out\n",
        "\n",
        "    def parameters(self):\n",
        "        return self.neurons\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Layer of [{', '.join(str(n) for n in self.neurons)}]\"\n",
        "\n",
        "class MLP(Module):\n",
        "\n",
        "    def __init__(self, nin, nouts, lr=0.01):\n",
        "        self.learning_rate = lr\n",
        "        sz = [nin] + nouts\n",
        "        self.layers = [Layer(sz[i], sz[i+1], nonlin=(i!=len(nouts)-1)) for i in range(len(nouts))]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        return reduce(lambda x, f: f(x), self.layers, x)\n",
        "\n",
        "\n",
        "    def parameters(self):\n",
        "        return [w for layer in self.layers for neuron in layer.parameters() for w in neuron.parameters()]\n",
        "\n",
        "    def __repr__(self):\n",
        "        repr = '\\n'.join(str(layer) for layer in self.layers)\n",
        "        return f\"MLP of [{repr}]\"\n",
        "    \n",
        "    def step(self):\n",
        "      for p in self.parameters():\n",
        "        p.data -= p.grad * self.learning_rate\n",
        "\n",
        "def MSELoss(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    assert n == len(y_pred)\n",
        "    return sum(map(lambda y_t, y_p: (y_t - y_p) ** 2, y_true, y_pred)) / n\n",
        "\n",
        "def softmax(y):\n",
        "    assert all(isinstance(yi, Value) for yi in y)\n",
        "    denominator = sum(yi.exp() for yi in y)\n",
        "    return [yi/denominator for yi in y]"
      ],
      "metadata": {
        "id": "rkl70dxhkcQN"
      },
      "execution_count": 963,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([4]*5)\n",
        "b = torch.tensor([2]*5)\n"
      ],
      "metadata": {
        "id": "QBn-nUuPN_zQ"
      },
      "execution_count": 949,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение многослойного перцептрона"
      ],
      "metadata": {
        "id": "YkkaE1V1m5i5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сам перцептрон"
      ],
      "metadata": {
        "id": "WWy-H8eCn2zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(3, [4, 4, 1], lr=0.1)\n",
        "print(model)\n",
        "print(\"number of parameters\", len(model.parameters()))"
      ],
      "metadata": {
        "id": "3La6nRi4m920",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04dc8171-8ed8-4543-9d55-c6459f0ad268"
      },
      "execution_count": 955,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP of [Layer of [ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3), ReLUNeuron(3)]\n",
            "Layer of [ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4), ReLUNeuron(4)]\n",
            "Layer of [LinearNeuron(4)]]\n",
            "number of parameters 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Набор данных"
      ],
      "metadata": {
        "id": "OvkZVOLcnvqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xs = [\n",
        "  [2.0, 3.0, -1.0],\n",
        "  [3.0, -1.0, 0.5],\n",
        "  [0.5, 1.0, 1.0],\n",
        "  [1.0, 1.0, -1.0],\n",
        "]\n",
        "ys = [1.0, -1.0, -1.0, 1.0] # desired targets"
      ],
      "metadata": {
        "id": "aLJULsNanpVC"
      },
      "execution_count": 956,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(20):\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    # forward\n",
        "    output = model(xs)\n",
        "\n",
        "    # calculate loss (mean square error)\n",
        "    loss = MSELoss(ys, output)\n",
        "\n",
        "    #calculate accuracy\n",
        "    acc = sum([ys[i] == round(output[i].data) for i in range(len(ys))]) / len(ys)\n",
        "    \n",
        "    # backward (zero_grad + backward)\n",
        "    loss.backward()\n",
        "    \n",
        "    # update\n",
        "    model.step()\n",
        "    \n",
        "    if k % 1 == 0:\n",
        "        print(f\"step {k} loss {loss.data}, accuracy {acc*100}%\")"
      ],
      "metadata": {
        "id": "OuCTaTB8n5l0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b926731-0ef7-4e57-9839-6daee78da634"
      },
      "execution_count": 961,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0 loss 0.9350804090839608, accuracy 0.0%\n",
            "step 1 loss 0.9276704473983346, accuracy 0.0%\n",
            "step 2 loss 0.919837728717381, accuracy 0.0%\n",
            "step 3 loss 0.9083112986142348, accuracy 0.0%\n",
            "step 4 loss 0.8807204005964395, accuracy 0.0%\n",
            "step 5 loss 0.8468607248904936, accuracy 0.0%\n",
            "step 6 loss 0.803219361410703, accuracy 0.0%\n",
            "step 7 loss 0.7454612660580766, accuracy 0.0%\n",
            "step 8 loss 0.676166898216835, accuracy 0.0%\n",
            "step 9 loss 0.5918984866261555, accuracy 0.0%\n",
            "step 10 loss 0.5010035985143396, accuracy 25.0%\n",
            "step 11 loss 0.41536587656552476, accuracy 50.0%\n",
            "step 12 loss 0.3424408883074549, accuracy 50.0%\n",
            "step 13 loss 0.28248008721298046, accuracy 50.0%\n",
            "step 14 loss 0.23255805647692654, accuracy 50.0%\n",
            "step 15 loss 0.1907723994896752, accuracy 50.0%\n",
            "step 16 loss 0.15603372843180174, accuracy 50.0%\n",
            "step 17 loss 0.12738754805976638, accuracy 75.0%\n",
            "step 18 loss 0.10392367831909585, accuracy 100.0%\n",
            "step 19 loss 0.08503892631808745, accuracy 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание"
      ],
      "metadata": {
        "id": "n4maaWL5yg-f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Домашнее задание 1.** Доделать практику. Оформить код в три отдельных модуля `autograd`, `nn`, `train`"
      ],
      "metadata": {
        "id": "2yyK39RYo084"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Домашнее задание 2 (Опционально).** Создать свою функцию softmax, наследуемую от `torch.autograd.Function` и имплементировать forward и backward проход. Сравнить со стандартной функцией в Pytorch. \n",
        "[Создание функций](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html) [Софтмакс](https://congyuzhou.medium.com/softmax-3408fb42d55a)"
      ],
      "metadata": {
        "id": "FdzPyQ-hylKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код"
      ],
      "metadata": {
        "id": "bGMpj9Pf61n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Домашнее задание 3 (Опционально).** Добавить функцию софтмакс в собственну библиотеку автоматического дифференцирования. Сравнить с пунктом 2"
      ],
      "metadata": {
        "id": "3VPpRO6H6SHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код"
      ],
      "metadata": {
        "id": "2YJfxtqSphFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Домашнее задание 4 (Опционально).** Добавить визуализацию обучения. Потом мы пройдем более подробно."
      ],
      "metadata": {
        "id": "nRRgw0HNsr_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.wandb.ai/guides/integrations/pytorch"
      ],
      "metadata": {
        "id": "W5AWW52REfn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.wandb.ai/ref/python/watch  "
      ],
      "metadata": {
        "id": "ekFfy3cWVOIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.wandb.ai/guides/track/jupyter"
      ],
      "metadata": {
        "id": "9G4SOp28ok0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "lumiR8oykL04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "Xw3c6P7BkP9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "run = wandb.init(project=\"polynom_learning_\")"
      ],
      "metadata": {
        "id": "udPv0ufwkxOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "id": "Xtpc9MAUodNs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}